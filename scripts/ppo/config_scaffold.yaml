# Logging configuration
experiment_name: acegen
agent_name: ppo
log_dir: results
logger_backend: null # csv, wandb, tensorboard, or null
seed: 101

# Environment configuration
num_envs: 64 # Number of smiles to generate in parallel
total_smiles: 10_000

# Scoring function
molscore: LibINVENT_Exp1
molscore_include: ["DRD2_SelRF_SubFilt_DF"]
custom_task: null # Requires molscore to be set to null

# Promptsmiles configuration
promptsmiles: N1(*)CCN(CC1)CCCCN(*)
promptsmiles_optimize: True
promptsmiles_shuffle: True
promptsmiles_multi: False

# Architecture configuration
shared_nets: False
model: gru # gru, lstm, or gpt2
# The default prior varies for each model. Refer to the README file in the root directory for more information.
# The default vocabulary varies for each prior. Refer to the README file in the root directory for more information.

# Optimizer configuration
lr: 0.0005
eps: 1.0e-06
weight_decay: 1.0e-06

# PPO configuration
gamma: 0.999
lmbda: 1.0 # GAE
critic_coef: 0.25
entropy_coef: 0.01
kl_coef: 0.001
ppo_epochs: 3
max_grad_norm: 0.25
ppo_clip: 0.5

# Data replay configuration
experience_replay: True # If True, the algorithm is PPO+D
replay_batch_size: 24
replay_buffer_size: 100
