# Logging configuration
experiment_name: Multi-Agent
agent_name: reinforce
log_dir: results/reinforce_2agents_0001_nograd # Directory to save the results
logger_backend: null  # wandb, tensorboard, or null
seed: [101, 102, 103, 104, 105] # multiple seeds can be provided as a list to multiple experiments sequentially e.g. [101, 102, 103]

# Environment configuration
num_agents: 5 # Number of agents
num_envs: 64 # Number of smiles to generate in parallel
total_smiles: 50_000 # Total number of smiles to generate

# Scoring function
molscore_mode: benchmark # single, benchmark, or curriculum
molscore_task: MolExp # task configuration (JSON), benchmark (preset only), or curriculum task (preset only)
molscore_kwargs:
  include: []
custom_task: null # Requires molscore to be set to null

# Promptsmiles configuration
prompt: null  # e.g. c1ccccc  # Fix the beginning of the generated molecules

# Model architecture
model: gru # gru, lstm, gpt2, mamba or llama2
# The default prior varies for each model. Refer to the README file in the root directory for more information.
# The default vocabulary varies for each prior. Refer to the README file in the root directory for more information.
custom_model_factory: null # Path to a custom model factory (e.g. my_module.create_model)

# Optimizer configuration
lr: 0.0005
eps: 1.0e-08
weight_decay: 0.0

# Algorithm configuration (not additional parameters for Reinforce)
entropy_coef: 0.001 # Coef 0.1 seems decent
chist_coef: 0.0 # Coef makes no diff, so just use 0, 1 for off, on

# Data replay configuration
experience_replay: True
replay_buffer_size: 100
replay_batch_size: 20
