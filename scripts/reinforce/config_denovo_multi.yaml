# Logging configuration
experiment_name: Multi-Agent
agent_name: reinforce-DF
log_dir: results/multi_agent # Directory to save the results
logger_backend: wandb  # wandb, tensorboard, or null
seed: 101 # multiple seeds can be provided as a list to multiple experiments sequentially e.g. [101, 102, 103]

# Environment configuration
num_agents: 2 # Number of agents
num_envs: 128 # Number of smiles to generate in parallel
total_smiles: 20_000 # Total number of smiles to generate

# Scoring function
molscore_mode: benchmark # single, benchmark, or curriculum
molscore_task: MolExp-DF # task configuration (JSON), benchmark (preset only), or curriculum task (preset only)
molscore_kwargs:
  include: ["AP-DF"]
custom_task: null # Requires molscore to be set to null

# Promptsmiles configuration
prompt: null  # e.g. c1ccccc  # Fix the beginning of the generated molecules

# Model architecture
model: gru # gru, lstm, gpt2, mamba or llama2
# The default prior varies for each model. Refer to the README file in the root directory for more information.
# The default vocabulary varies for each prior. Refer to the README file in the root directory for more information.
custom_model_factory: null # Path to a custom model factory (e.g. my_module.create_model)

# Optimizer configuration
lr: 0.0001
eps: 1.0e-08
weight_decay: 0.0

# Algorithm configuration (not additional parameters for Reinforce)
entropy_coef: 0.0
chist_coef: 0.0 # Coef makes no diff, so just use 0, 1 for off, on

# Data replay configuration
experience_replay: True
replay_buffer_size: 100
replay_batch_size: 10
